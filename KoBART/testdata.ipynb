{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 데이터 2000개 보고서 연설문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make index list\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "json_data=[]\n",
    "psg_tsv = [] # 원본\n",
    "psg_tsv_str=[]\n",
    "smy_tsv = [] # 요약\n",
    "smy_tsv_str=[]\n",
    "\n",
    "def listToString(str_list):\n",
    "    result = \"\"\n",
    "    for s in str_list:\n",
    "        result += s + \" \"\n",
    "    return result.strip()\n",
    "\n",
    "with open('./dacondata/test.json') as f:\n",
    "    for line in f:\n",
    "        # line은 String 값 \n",
    "        json_data.append(json.loads(line)) # 전체데이터 딕셔너리 형태로 넣기 \n",
    "\n",
    "    num = 0\n",
    "    for json_num_list in json_data:\n",
    "        #print(type(i))\n",
    "        #print(json_data[0]) # {'id': '365247698', 'abstractive': ['이해찬 대표가 조국 사태와 관련 송구한 입장 표명이 과감한 인적 쇄신으로 이어져야 한다.'],.....\n",
    "        #print(json_num_list) # 2000개\n",
    "\n",
    "        #print(json_data[0]['abstractive'])\n",
    "        #print(listToString(json_data[0]['article_original']))\n",
    "\n",
    "        psg_tsv.append(json_data[num]['article_original']) # 데이터 원문입니다.\n",
    "        psg_tsv_str.append(listToString(psg_tsv[num]))\n",
    "        #psg_tsv_str.append(listToString(psg_tsv[num]).replace(\"\\\\\",\"\")) #데이터 원문 string으로 출력\n",
    "        #psg_tsv_str.append(re.sub('[\\[\\]()\\/<>\\{\\}]+' ,'', listToString(psg_tsv[num]))) #데이터 원문 string으로 출력\n",
    "        #re.sub('[\\[\\]()\\/]+' ,'', listToString(psg_tsv[num]))\n",
    "\n",
    "        smy_tsv.append(json_data[num]['abstractive'])\n",
    "        #smy_tsv_str.append(  re.sub('[\\[\\]()\\/<>\\{\\}]+' ,'', listToString(smy_tsv[num])))\n",
    "        #smy_tsv_str.append(listToString(smy_tsv[num]).replace(\"\\\\\",\"\"))\n",
    "        #re.sub('[\\[\\]()\\/]+' ,'', listToString(smy_tsv[num]))\n",
    "    \n",
    "        num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부...</td>\n",
       "      <td>이해찬 대표가 조국 사태와 관련 송구한 입장 표명이 과감한 인적 쇄신으로 이어져야 한다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>탈원전 정책에서 비롯된 한국전력의 경영 부담이 결국 전기료 인상을 초래하게 됐다. ...</td>\n",
       "      <td>탈원전 정책에서 비롯된 한국전력의 경영 악화가 결국 전기료 인상이라는 결과를 낳아 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>북한이 그제 금강산국제관광국 명의로 통일부와 현대아산에 통지문을 보내 금강산관광 시...</td>\n",
       "      <td>북한이 통일부와 현대아산에 금강산 관광 시설 철거와 관련하여 문서 교환 방식의 협의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지난달 한국의 소비자물가상승률이 경제협력개발기구(OECD) 회원국 중 가장 낮았다....</td>\n",
       "      <td>OECD가 집계한 소비자물가 통게에서 9월 한국 상승률은 전년 동월 대비 -0.4%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김종갑 한국전력 사장이 1 조1 천억원이 넘는 각종 전기료 특례 할인을 모두 폐지하...</td>\n",
       "      <td>김종갑 한국전력 사장이 1조 1천억원 규모의 전기료 특례 할인 폐지 및 전기요금 원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>최근 만덕2터널에서 발생한 4중 추돌사고 아찔한 순간이 공개됐다. 쏘렌토 차주 A ...</td>\n",
       "      <td>부산 만덕 2터널에서 4중 추돌사고를 당한 쏘렌토 차주 A씨가 공개한 사고 순간 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>지난해 국내 손해보험사들의 대리점 수수료가 고공행진한 것으로 나타났다. 17일 손해...</td>\n",
       "      <td>17일 손해보험협회에 의하면 독립법인대리점을 통한 보험 판매가 늘면서 지난해 10개...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>LG전자가 와인 113병을 보관할 수 있는 24인치 컬럼형 '와인셀러'를 출시했다고...</td>\n",
       "      <td>LG전자는 와인을 최적으로 보관가능한 동굴 기술을 적용한 컬럼형 와인셀러 초프리미엄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...</td>\n",
       "      <td>주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>경북지역은 경쟁력 있는 과일브랜드를 육성하기 위해 2016년부터 '데일리(daily...</td>\n",
       "      <td>최근 수입 농산물 증가와 지역 지역별 군소 브랜드의 난립이 국산 농산물의 경쟁력을 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                passage  \\\n",
       "0     더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부...   \n",
       "1     탈원전 정책에서 비롯된 한국전력의 경영 부담이 결국 전기료 인상을 초래하게 됐다. ...   \n",
       "2     북한이 그제 금강산국제관광국 명의로 통일부와 현대아산에 통지문을 보내 금강산관광 시...   \n",
       "3     지난달 한국의 소비자물가상승률이 경제협력개발기구(OECD) 회원국 중 가장 낮았다....   \n",
       "4     김종갑 한국전력 사장이 1 조1 천억원이 넘는 각종 전기료 특례 할인을 모두 폐지하...   \n",
       "...                                                 ...   \n",
       "1995  최근 만덕2터널에서 발생한 4중 추돌사고 아찔한 순간이 공개됐다. 쏘렌토 차주 A ...   \n",
       "1996  지난해 국내 손해보험사들의 대리점 수수료가 고공행진한 것으로 나타났다. 17일 손해...   \n",
       "1997  LG전자가 와인 113병을 보관할 수 있는 24인치 컬럼형 '와인셀러'를 출시했다고...   \n",
       "1998  주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...   \n",
       "1999  경북지역은 경쟁력 있는 과일브랜드를 육성하기 위해 2016년부터 '데일리(daily...   \n",
       "\n",
       "                                                summary  \n",
       "0     이해찬 대표가 조국 사태와 관련 송구한 입장 표명이 과감한 인적 쇄신으로 이어져야 한다.  \n",
       "1     탈원전 정책에서 비롯된 한국전력의 경영 악화가 결국 전기료 인상이라는 결과를 낳아 ...  \n",
       "2     북한이 통일부와 현대아산에 금강산 관광 시설 철거와 관련하여 문서 교환 방식의 협의...  \n",
       "3     OECD가 집계한 소비자물가 통게에서 9월 한국 상승률은 전년 동월 대비 -0.4%...  \n",
       "4     김종갑 한국전력 사장이 1조 1천억원 규모의 전기료 특례 할인 폐지 및 전기요금 원...  \n",
       "...                                                 ...  \n",
       "1995  부산 만덕 2터널에서 4중 추돌사고를 당한 쏘렌토 차주 A씨가 공개한 사고 순간 영...  \n",
       "1996  17일 손해보험협회에 의하면 독립법인대리점을 통한 보험 판매가 늘면서 지난해 10개...  \n",
       "1997  LG전자는 와인을 최적으로 보관가능한 동굴 기술을 적용한 컬럼형 와인셀러 초프리미엄...  \n",
       "1998  주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...  \n",
       "1999  최근 수입 농산물 증가와 지역 지역별 군소 브랜드의 난립이 국산 농산물의 경쟁력을 ...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labeling = pd.concat([pd.DataFrame(psg_tsv_str),pd.DataFrame(smy_tsv)], axis = 1)\n",
    "test_labeling.columns = ['passage' ,'summary'] # 뉴스 학습데이터 양식 맞추기 (원문  요약문 => 탭 구분)\n",
    "test_labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passage    0\n",
       "summary    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#결측치 제거\n",
    "test_labeling.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부...</td>\n",
       "      <td>이해찬 대표가 조국 사태와 관련 송구한 입장 표명이 과감한 인적 쇄신으로 이어져야 한다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>탈원전 정책에서 비롯된 한국전력의 경영 부담이 결국 전기료 인상을 초래하게 됐다. ...</td>\n",
       "      <td>탈원전 정책에서 비롯된 한국전력의 경영 악화가 결국 전기료 인상이라는 결과를 낳아 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>북한이 그제 금강산국제관광국 명의로 통일부와 현대아산에 통지문을 보내 금강산관광 시...</td>\n",
       "      <td>북한이 통일부와 현대아산에 금강산 관광 시설 철거와 관련하여 문서 교환 방식의 협의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지난달 한국의 소비자물가상승률이 경제협력개발기구(OECD) 회원국 중 가장 낮았다....</td>\n",
       "      <td>OECD가 집계한 소비자물가 통게에서 9월 한국 상승률은 전년 동월 대비 -0.4%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김종갑 한국전력 사장이 1 조1 천억원이 넘는 각종 전기료 특례 할인을 모두 폐지하...</td>\n",
       "      <td>김종갑 한국전력 사장이 1조 1천억원 규모의 전기료 특례 할인 폐지 및 전기요금 원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>최근 만덕2터널에서 발생한 4중 추돌사고 아찔한 순간이 공개됐다. 쏘렌토 차주 A ...</td>\n",
       "      <td>부산 만덕 2터널에서 4중 추돌사고를 당한 쏘렌토 차주 A씨가 공개한 사고 순간 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>지난해 국내 손해보험사들의 대리점 수수료가 고공행진한 것으로 나타났다. 17일 손해...</td>\n",
       "      <td>17일 손해보험협회에 의하면 독립법인대리점을 통한 보험 판매가 늘면서 지난해 10개...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>LG전자가 와인 113병을 보관할 수 있는 24인치 컬럼형 '와인셀러'를 출시했다고...</td>\n",
       "      <td>LG전자는 와인을 최적으로 보관가능한 동굴 기술을 적용한 컬럼형 와인셀러 초프리미엄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...</td>\n",
       "      <td>주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>경북지역은 경쟁력 있는 과일브랜드를 육성하기 위해 2016년부터 '데일리(daily...</td>\n",
       "      <td>최근 수입 농산물 증가와 지역 지역별 군소 브랜드의 난립이 국산 농산물의 경쟁력을 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                passage  \\\n",
       "0     더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부...   \n",
       "1     탈원전 정책에서 비롯된 한국전력의 경영 부담이 결국 전기료 인상을 초래하게 됐다. ...   \n",
       "2     북한이 그제 금강산국제관광국 명의로 통일부와 현대아산에 통지문을 보내 금강산관광 시...   \n",
       "3     지난달 한국의 소비자물가상승률이 경제협력개발기구(OECD) 회원국 중 가장 낮았다....   \n",
       "4     김종갑 한국전력 사장이 1 조1 천억원이 넘는 각종 전기료 특례 할인을 모두 폐지하...   \n",
       "...                                                 ...   \n",
       "1995  최근 만덕2터널에서 발생한 4중 추돌사고 아찔한 순간이 공개됐다. 쏘렌토 차주 A ...   \n",
       "1996  지난해 국내 손해보험사들의 대리점 수수료가 고공행진한 것으로 나타났다. 17일 손해...   \n",
       "1997  LG전자가 와인 113병을 보관할 수 있는 24인치 컬럼형 '와인셀러'를 출시했다고...   \n",
       "1998  주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...   \n",
       "1999  경북지역은 경쟁력 있는 과일브랜드를 육성하기 위해 2016년부터 '데일리(daily...   \n",
       "\n",
       "                                                summary  \n",
       "0     이해찬 대표가 조국 사태와 관련 송구한 입장 표명이 과감한 인적 쇄신으로 이어져야 한다.  \n",
       "1     탈원전 정책에서 비롯된 한국전력의 경영 악화가 결국 전기료 인상이라는 결과를 낳아 ...  \n",
       "2     북한이 통일부와 현대아산에 금강산 관광 시설 철거와 관련하여 문서 교환 방식의 협의...  \n",
       "3     OECD가 집계한 소비자물가 통게에서 9월 한국 상승률은 전년 동월 대비 -0.4%...  \n",
       "4     김종갑 한국전력 사장이 1조 1천억원 규모의 전기료 특례 할인 폐지 및 전기요금 원...  \n",
       "...                                                 ...  \n",
       "1995  부산 만덕 2터널에서 4중 추돌사고를 당한 쏘렌토 차주 A씨가 공개한 사고 순간 영...  \n",
       "1996  17일 손해보험협회에 의하면 독립법인대리점을 통한 보험 판매가 늘면서 지난해 10개...  \n",
       "1997  LG전자는 와인을 최적으로 보관가능한 동굴 기술을 적용한 컬럼형 와인셀러 초프리미엄...  \n",
       "1998  주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...  \n",
       "1999  최근 수입 농산물 증가와 지역 지역별 군소 브랜드의 난립이 국산 농산물의 경쟁력을 ...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labeling.dropna(axis=0)\n",
    "test_labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labeling.to_csv('./dacondata/test.tsv',index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'기자 이름 어쩌구     저쩌구 '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub('[\\[\\]()\\/<>]+' ,'', '[기자 이름] /(어쩌구)/ < < > > /저쩌구/ ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rouge 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import platform\n",
    "import itertools\n",
    "import collections\n",
    "import pkg_resources  # pip install py-rouge\n",
    "from io import open\n",
    "from konlpy.tag import Okt, Komoran, Mecab, Hannanum, Kkma\n",
    "# import MeCab\n",
    "\n",
    "\n",
    "class Rouge:\n",
    "    DEFAULT_METRICS = {\"rouge-n\"}\n",
    "    DEFAULT_N = 2\n",
    "    STATS = [\"f\", \"p\", \"r\"]\n",
    "    AVAILABLE_METRICS = {\"rouge-n\", \"rouge-l\", \"rouge-w\"}\n",
    "    AVAILABLE_LENGTH_LIMIT_TYPES = {\"words\", \"bytes\"}\n",
    "    REMOVE_CHAR_PATTERN = re.compile(\"[^A-Za-z0-9가-힣]\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        metrics=None,\n",
    "        max_n=2,  # n-gram의 최대 크기를 지정하는 정수값. Rouge-n 메트릭을 사용하지 않을 때 None\n",
    "        limit_length=True,  # 요약문과 참조문의 길이를 제한할지 여부를 나타내는 불리언\n",
    "        length_limit=1000,  # 요약문과 참조문의 최대 길이를 지정하는 정수값\n",
    "        length_limit_type=\"words\",  # length_limit의 단위를 지정함. words 또는 bytes 선택 가능\n",
    "        apply_avg=True,  # 여러 문장들의 평균 Rouge 점수를 사용할지 여부를 나타냄\n",
    "        apply_best=False,  # 여러 문장들 중에서 가장 높은 Rouge 점수를 사용할지 여부\n",
    "        use_tokenizer=True,  # 문장을 토큰화할지 여부를 나타냄\n",
    "        alpha=0.5,  # Rouge-l 메트릭에서 사용되는 가중치 매개변수로 [0,1] 범위의 실수값\n",
    "        weight_factor=1.0,  # Rouge-w 메트릭에서 사용되는 가중치 매개변수\n",
    "    ):\n",
    "        self.metrics = metrics[:] if metrics is not None else Rouge.DEFAULT_METRICS\n",
    "        for m in self.metrics:\n",
    "            if m not in Rouge.AVAILABLE_METRICS:\n",
    "                raise ValueError(\"Unknown metric '{}'\".format(m))\n",
    "\n",
    "        self.max_n = max_n if \"rouge-n\" in self.metrics else None\n",
    "        # Add all rouge-n metrics\n",
    "        if self.max_n is not None:\n",
    "            index_rouge_n = self.metrics.index(\"rouge-n\")\n",
    "            del self.metrics[index_rouge_n]\n",
    "            self.metrics += [\"rouge-{}\".format(n)\n",
    "                             for n in range(1, self.max_n + 1)]\n",
    "        self.metrics = set(self.metrics)\n",
    "\n",
    "        self.limit_length = limit_length\n",
    "        if self.limit_length:\n",
    "            if length_limit_type not in Rouge.AVAILABLE_LENGTH_LIMIT_TYPES:\n",
    "                raise ValueError(\n",
    "                    \"Unknown length_limit_type '{}'\".format(length_limit_type))\n",
    "\n",
    "        self.length_limit = length_limit\n",
    "        if self.length_limit == 0:\n",
    "            self.limit_length = False\n",
    "        self.length_limit_type = length_limit_type\n",
    "\n",
    "        self.use_tokenizer = use_tokenizer\n",
    "        if use_tokenizer:\n",
    "            self.tokenizer = Mecab(dicpath=r\"C:\\mecab\\mecab-ko-dic\")\n",
    "\n",
    "        self.apply_avg = apply_avg\n",
    "        self.apply_best = apply_best\n",
    "        self.alpha = alpha\n",
    "        self.weight_factor = weight_factor\n",
    "        if self.weight_factor <= 0:\n",
    "            raise ValueError(\"ROUGE-W weight factor must greater than 0.\")\n",
    "\n",
    "    def tokenize_text(self, text):\n",
    "        if self.use_tokenizer:\n",
    "            return self.tokenizer.morphs(text)\n",
    "        else:\n",
    "            return text\n",
    "\n",
    "    @staticmethod\n",
    "    def split_into_sentences(text):\n",
    "        return text.split(\"\\n\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_ngrams(n, text):\n",
    "        ngram_set = collections.defaultdict(int)\n",
    "        max_index_ngram_start = len(text) - n\n",
    "        for i in range(max_index_ngram_start + 1):\n",
    "            ngram_set[tuple(text[i: i + n])] += 1\n",
    "        return ngram_set\n",
    "\n",
    "    @staticmethod\n",
    "    def _split_into_words(sentences):\n",
    "        return list(itertools.chain(*[_.split() for _ in sentences]))\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_word_ngrams_and_length(n, sentences):\n",
    "        assert len(sentences) > 0\n",
    "        assert n > 0\n",
    "\n",
    "        tokens = Rouge._split_into_words(sentences)\n",
    "        return Rouge._get_ngrams(n, tokens), tokens, len(tokens) - (n - 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_unigrams(sentences):\n",
    "        assert len(sentences) > 0\n",
    "\n",
    "        tokens = Rouge._split_into_words(sentences)\n",
    "        unigram_set = collections.defaultdict(int)\n",
    "        for token in tokens:\n",
    "            unigram_set[token] += 1\n",
    "        return unigram_set, len(tokens)\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_p_r_f_score(\n",
    "        evaluated_count,\n",
    "        reference_count,\n",
    "        overlapping_count,\n",
    "        alpha=0.5,\n",
    "        weight_factor=1.0,\n",
    "    ):\n",
    "        precision = 0.0 if evaluated_count == 0 else overlapping_count / \\\n",
    "            float(evaluated_count)\n",
    "        if weight_factor != 1.0:\n",
    "            precision = precision ** (1.0 / weight_factor)\n",
    "        recall = 0.0 if reference_count == 0 else overlapping_count / \\\n",
    "            float(reference_count)\n",
    "        if weight_factor != 1.0:\n",
    "            recall = recall ** (1.0 / weight_factor)\n",
    "        f1_score = Rouge._compute_f_score(precision, recall, alpha)\n",
    "        return {\"f\": f1_score, \"p\": precision, \"r\": recall}\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_f_score(precision, recall, alpha=0.5):\n",
    "        return (\n",
    "            0.0\n",
    "            if (recall == 0.0 or precision == 0.0)\n",
    "            else precision * recall / ((1 - alpha) * precision + alpha * recall)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_ngrams(evaluated_sentences, reference_sentences, n):\n",
    "        if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n",
    "            raise ValueError(\"Collections must contain at least 1 sentence.\")\n",
    "\n",
    "        evaluated_ngrams, _, evaluated_count = Rouge._get_word_ngrams_and_length(\n",
    "            n, evaluated_sentences\n",
    "        )\n",
    "        reference_ngrams, _, reference_count = Rouge._get_word_ngrams_and_length(\n",
    "            n, reference_sentences\n",
    "        )\n",
    "\n",
    "        # Gets the overlapping ngrams between evaluated and reference\n",
    "        overlapping_ngrams = set(evaluated_ngrams.keys()).intersection(\n",
    "            set(reference_ngrams.keys()))\n",
    "        overlapping_count = 0\n",
    "        for ngram in overlapping_ngrams:\n",
    "            overlapping_count += min(evaluated_ngrams[ngram],\n",
    "                                     reference_ngrams[ngram])\n",
    "\n",
    "        return evaluated_count, reference_count, overlapping_count\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_ngrams_lcs(evaluated_sentences, reference_sentences, weight_factor=1.0):\n",
    "        def _lcs(x, y):\n",
    "            m = len(x)\n",
    "            n = len(y)\n",
    "            vals = collections.defaultdict(int)\n",
    "            dirs = collections.defaultdict(int)\n",
    "\n",
    "            for i in range(1, m + 1):\n",
    "                for j in range(1, n + 1):\n",
    "                    if x[i - 1] == y[j - 1]:\n",
    "                        vals[i, j] = vals[i - 1, j - 1] + 1\n",
    "                        dirs[i, j] = \"|\"\n",
    "                    elif vals[i - 1, j] >= vals[i, j - 1]:\n",
    "                        vals[i, j] = vals[i - 1, j]\n",
    "                        dirs[i, j] = \"^\"\n",
    "                    else:\n",
    "                        vals[i, j] = vals[i, j - 1]\n",
    "                        dirs[i, j] = \"<\"\n",
    "\n",
    "            return vals, dirs\n",
    "\n",
    "        def _wlcs(x, y, weight_factor):\n",
    "            m = len(x)\n",
    "            n = len(y)\n",
    "            vals = collections.defaultdict(float)\n",
    "            dirs = collections.defaultdict(int)\n",
    "            lengths = collections.defaultdict(int)\n",
    "\n",
    "            for i in range(1, m + 1):\n",
    "                for j in range(1, n + 1):\n",
    "                    if x[i - 1] == y[j - 1]:\n",
    "                        length_tmp = lengths[i - 1, j - 1]\n",
    "                        vals[i, j] = (\n",
    "                            vals[i - 1, j - 1]\n",
    "                            + (length_tmp + 1) ** weight_factor\n",
    "                            - length_tmp ** weight_factor\n",
    "                        )\n",
    "                        dirs[i, j] = \"|\"\n",
    "                        lengths[i, j] = length_tmp + 1\n",
    "                    elif vals[i - 1, j] >= vals[i, j - 1]:\n",
    "                        vals[i, j] = vals[i - 1, j]\n",
    "                        dirs[i, j] = \"^\"\n",
    "                        lengths[i, j] = 0\n",
    "                    else:\n",
    "                        vals[i, j] = vals[i, j - 1]\n",
    "                        dirs[i, j] = \"<\"\n",
    "                        lengths[i, j] = 0\n",
    "\n",
    "            return vals, dirs\n",
    "\n",
    "        def _mark_lcs(mask, dirs, m, n):\n",
    "            while m != 0 and n != 0:\n",
    "                if dirs[m, n] == \"|\":\n",
    "                    m -= 1\n",
    "                    n -= 1\n",
    "                    mask[m] = 1\n",
    "                elif dirs[m, n] == \"^\":\n",
    "                    m -= 1\n",
    "                elif dirs[m, n] == \"<\":\n",
    "                    n -= 1\n",
    "                else:\n",
    "                    raise UnboundLocalError(\"Illegal move\")\n",
    "\n",
    "            return mask\n",
    "\n",
    "        if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n",
    "            raise ValueError(\"Collections must contain at least 1 sentence.\")\n",
    "\n",
    "        evaluated_unigrams_dict, evaluated_count = Rouge._get_unigrams(\n",
    "            evaluated_sentences)\n",
    "        reference_unigrams_dict, reference_count = Rouge._get_unigrams(\n",
    "            reference_sentences)\n",
    "\n",
    "        # Has to use weight factor for WLCS\n",
    "        use_WLCS = weight_factor != 1.0\n",
    "        if use_WLCS:\n",
    "            evaluated_count = evaluated_count ** weight_factor\n",
    "            reference_count = 0\n",
    "\n",
    "        overlapping_count = 0.0\n",
    "        for reference_sentence in reference_sentences:\n",
    "            reference_sentence_tokens = reference_sentence.split()\n",
    "            if use_WLCS:\n",
    "                reference_count += len(reference_sentence_tokens) ** weight_factor\n",
    "            hit_mask = [0 for _ in range(len(reference_sentence_tokens))]\n",
    "\n",
    "            for evaluated_sentence in evaluated_sentences:\n",
    "                evaluated_sentence_tokens = evaluated_sentence.split()\n",
    "\n",
    "                if use_WLCS:\n",
    "                    _, lcs_dirs = _wlcs(\n",
    "                        reference_sentence_tokens,\n",
    "                        evaluated_sentence_tokens,\n",
    "                        weight_factor,\n",
    "                    )\n",
    "                else:\n",
    "                    _, lcs_dirs = _lcs(\n",
    "                        reference_sentence_tokens, evaluated_sentence_tokens)\n",
    "                _mark_lcs(\n",
    "                    hit_mask,\n",
    "                    lcs_dirs,\n",
    "                    len(reference_sentence_tokens),\n",
    "                    len(evaluated_sentence_tokens),\n",
    "                )\n",
    "\n",
    "            overlapping_count_length = 0\n",
    "            for ref_token_id, val in enumerate(hit_mask):\n",
    "                if val == 1:\n",
    "                    token = reference_sentence_tokens[ref_token_id]\n",
    "                    if evaluated_unigrams_dict[token] > 0 and reference_unigrams_dict[token] > 0:\n",
    "                        evaluated_unigrams_dict[token] -= 1\n",
    "                        reference_unigrams_dict[ref_token_id] -= 1\n",
    "\n",
    "                        if use_WLCS:\n",
    "                            overlapping_count_length += 1\n",
    "                            if (\n",
    "                                ref_token_id +\n",
    "                                    1 < len(\n",
    "                                        hit_mask) and hit_mask[ref_token_id + 1] == 0\n",
    "                            ) or ref_token_id + 1 == len(hit_mask):\n",
    "                                overlapping_count += overlapping_count_length ** weight_factor\n",
    "                                overlapping_count_length = 0\n",
    "                        else:\n",
    "                            overlapping_count += 1\n",
    "\n",
    "        if use_WLCS:\n",
    "            reference_count = reference_count ** weight_factor\n",
    "\n",
    "        return evaluated_count, reference_count, overlapping_count\n",
    "\n",
    "    def get_scores(self, hypothesis, references):\n",
    "        if isinstance(hypothesis, str):\n",
    "            hypothesis, references = [hypothesis], [references]\n",
    "\n",
    "        if type(hypothesis) != type(references):\n",
    "            raise ValueError(\"'hyps' and 'refs' are not of the same type\")\n",
    "\n",
    "        if len(hypothesis) != len(references):\n",
    "            raise ValueError(\"'hyps' and 'refs' do not have the same length\")\n",
    "        scores = {}\n",
    "        has_rouge_n_metric = (\n",
    "            len([metric for metric in self.metrics if metric.split(\n",
    "                \"-\")[-1].isdigit()]) > 0\n",
    "        )\n",
    "        if has_rouge_n_metric:\n",
    "            scores.update(self._get_scores_rouge_n(hypothesis, references))\n",
    "            # scores = {**scores, **self._get_scores_rouge_n(hypothesis, references)}\n",
    "\n",
    "        has_rouge_l_metric = (\n",
    "            len([metric for metric in self.metrics if metric.split(\n",
    "                \"-\")[-1].lower() == \"l\"]) > 0\n",
    "        )\n",
    "        if has_rouge_l_metric:\n",
    "            scores.update(self._get_scores_rouge_l_or_w(\n",
    "                hypothesis, references, False))\n",
    "            # scores = {**scores, **self._get_scores_rouge_l_or_w(hypothesis, references, False)}\n",
    "\n",
    "        has_rouge_w_metric = (\n",
    "            len([metric for metric in self.metrics if metric.split(\n",
    "                \"-\")[-1].lower() == \"w\"]) > 0\n",
    "        )\n",
    "        if has_rouge_w_metric:\n",
    "            scores.update(self._get_scores_rouge_l_or_w(\n",
    "                hypothesis, references, True))\n",
    "            # scores = {**scores, **self._get_scores_rouge_l_or_w(hypothesis, references, True)}\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def _get_scores_rouge_n(self, all_hypothesis, all_references):\n",
    "        metrics = [metric for metric in self.metrics if metric.split(\n",
    "            \"-\")[-1].isdigit()]\n",
    "\n",
    "        if self.apply_avg or self.apply_best:\n",
    "            scores = {metric: {stat: 0.0 for stat in Rouge.STATS}\n",
    "                      for metric in metrics}\n",
    "        else:\n",
    "            scores = {\n",
    "                metric: [{stat: [] for stat in Rouge.STATS}\n",
    "                         for _ in range(len(all_hypothesis))]\n",
    "                for metric in metrics\n",
    "            }\n",
    "\n",
    "        for sample_id, (hypothesis, references) in enumerate(zip(all_hypothesis, all_references)):\n",
    "            assert isinstance(hypothesis, str)\n",
    "            has_multiple_references = False\n",
    "            if isinstance(references, list):\n",
    "                has_multiple_references = len(references) > 1\n",
    "                if not has_multiple_references:\n",
    "                    references = references[0]\n",
    "\n",
    "            # Prepare hypothesis and reference(s)\n",
    "            hypothesis = self._preprocess_summary_as_a_whole(hypothesis)\n",
    "            references = (\n",
    "                [self._preprocess_summary_as_a_whole(\n",
    "                    reference) for reference in references]\n",
    "                if has_multiple_references\n",
    "                else [self._preprocess_summary_as_a_whole(references)]\n",
    "            )\n",
    "\n",
    "            # Compute scores\n",
    "            for metric in metrics:\n",
    "                suffix = metric.split(\"-\")[-1]\n",
    "                n = int(suffix)\n",
    "\n",
    "                # Aggregate\n",
    "                if self.apply_avg:\n",
    "                    # average model\n",
    "                    total_hypothesis_ngrams_count = 0\n",
    "                    total_reference_ngrams_count = 0\n",
    "                    total_ngrams_overlapping_count = 0\n",
    "\n",
    "                    for reference in references:\n",
    "                        (\n",
    "                            hypothesis_count,\n",
    "                            reference_count,\n",
    "                            overlapping_ngrams,\n",
    "                        ) = Rouge._compute_ngrams(hypothesis, reference, n)\n",
    "                        total_hypothesis_ngrams_count += hypothesis_count\n",
    "                        total_reference_ngrams_count += reference_count\n",
    "                        total_ngrams_overlapping_count += overlapping_ngrams\n",
    "\n",
    "                    score = Rouge._compute_p_r_f_score(\n",
    "                        total_hypothesis_ngrams_count,\n",
    "                        total_reference_ngrams_count,\n",
    "                        total_ngrams_overlapping_count,\n",
    "                        self.alpha,\n",
    "                    )\n",
    "\n",
    "                    for stat in Rouge.STATS:\n",
    "                        scores[metric][stat] += score[stat]\n",
    "                else:\n",
    "                    # Best model\n",
    "                    if self.apply_best:\n",
    "                        best_current_score = None\n",
    "                        for reference in references:\n",
    "                            (\n",
    "                                hypothesis_count,\n",
    "                                reference_count,\n",
    "                                overlapping_ngrams,\n",
    "                            ) = Rouge._compute_ngrams(hypothesis, reference, n)\n",
    "                            score = Rouge._compute_p_r_f_score(\n",
    "                                hypothesis_count,\n",
    "                                reference_count,\n",
    "                                overlapping_ngrams,\n",
    "                                self.alpha,\n",
    "                            )\n",
    "                            if best_current_score is None or score[\"r\"] > best_current_score[\"r\"]:\n",
    "                                best_current_score = score\n",
    "\n",
    "                        for stat in Rouge.STATS:\n",
    "                            scores[metric][stat] += best_current_score[stat]\n",
    "                    # Keep all\n",
    "                    else:\n",
    "                        for reference in references:\n",
    "                            (\n",
    "                                hypothesis_count,\n",
    "                                reference_count,\n",
    "                                overlapping_ngrams,\n",
    "                            ) = Rouge._compute_ngrams(hypothesis, reference, n)\n",
    "                            score = Rouge._compute_p_r_f_score(\n",
    "                                hypothesis_count,\n",
    "                                reference_count,\n",
    "                                overlapping_ngrams,\n",
    "                                self.alpha,\n",
    "                            )\n",
    "                            for stat in Rouge.STATS:\n",
    "                                scores[metric][sample_id][stat].append(\n",
    "                                    score[stat])\n",
    "\n",
    "        # Compute final score with the average or the the max\n",
    "        if (self.apply_avg or self.apply_best) and len(all_hypothesis) > 1:\n",
    "            for metric in metrics:\n",
    "                for stat in Rouge.STATS:\n",
    "                    scores[metric][stat] /= len(all_hypothesis)\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def _get_scores_rouge_l_or_w(self, all_hypothesis, all_references, use_w=False):\n",
    "        metric = \"rouge-w\" if use_w else \"rouge-l\"\n",
    "        if self.apply_avg or self.apply_best:\n",
    "            scores = {metric: {stat: 0.0 for stat in Rouge.STATS}}\n",
    "        else:\n",
    "            scores = {\n",
    "                metric: [{stat: [] for stat in Rouge.STATS}\n",
    "                         for _ in range(len(all_hypothesis))]\n",
    "            }\n",
    "\n",
    "        for sample_id, (hypothesis_sentences, references_sentences) in enumerate(\n",
    "            zip(all_hypothesis, all_references)\n",
    "        ):\n",
    "            assert isinstance(hypothesis_sentences, str)\n",
    "            has_multiple_references = False\n",
    "            if isinstance(references_sentences, list):\n",
    "                has_multiple_references = len(references_sentences) > 1\n",
    "                if not has_multiple_references:\n",
    "                    references_sentences = references_sentences[0]\n",
    "\n",
    "            # Prepare hypothesis and reference(s)\n",
    "            hypothesis_sentences = self._preprocess_summary_per_sentence(\n",
    "                hypothesis_sentences)\n",
    "            references_sentences = (\n",
    "                [\n",
    "                    self._preprocess_summary_per_sentence(reference)\n",
    "                    for reference in references_sentences\n",
    "                ]\n",
    "                if has_multiple_references\n",
    "                else [self._preprocess_summary_per_sentence(references_sentences)]\n",
    "            )\n",
    "\n",
    "            # Compute scores\n",
    "            # Aggregate\n",
    "            if self.apply_avg:\n",
    "                # average model\n",
    "                total_hypothesis_ngrams_count = 0\n",
    "                total_reference_ngrams_count = 0\n",
    "                total_ngrams_overlapping_count = 0\n",
    "\n",
    "                for reference_sentences in references_sentences:\n",
    "                    (\n",
    "                        hypothesis_count,\n",
    "                        reference_count,\n",
    "                        overlapping_ngrams,\n",
    "                    ) = Rouge._compute_ngrams_lcs(\n",
    "                        hypothesis_sentences,\n",
    "                        reference_sentences,\n",
    "                        self.weight_factor if use_w else 1.0,\n",
    "                    )\n",
    "                    total_hypothesis_ngrams_count += hypothesis_count\n",
    "                    total_reference_ngrams_count += reference_count\n",
    "                    total_ngrams_overlapping_count += overlapping_ngrams\n",
    "\n",
    "                score = Rouge._compute_p_r_f_score(\n",
    "                    total_hypothesis_ngrams_count,\n",
    "                    total_reference_ngrams_count,\n",
    "                    total_ngrams_overlapping_count,\n",
    "                    self.alpha,\n",
    "                    self.weight_factor if use_w else 1.0,\n",
    "                )\n",
    "                for stat in Rouge.STATS:\n",
    "                    scores[metric][stat] += score[stat]\n",
    "            else:\n",
    "                # Best model\n",
    "                if self.apply_best:\n",
    "                    best_current_score = None\n",
    "                    best_current_score_wlcs = None\n",
    "                    for reference_sentences in references_sentences:\n",
    "                        (\n",
    "                            hypothesis_count,\n",
    "                            reference_count,\n",
    "                            overlapping_ngrams,\n",
    "                        ) = Rouge._compute_ngrams_lcs(\n",
    "                            hypothesis_sentences,\n",
    "                            reference_sentences,\n",
    "                            self.weight_factor if use_w else 1.0,\n",
    "                        )\n",
    "                        score = Rouge._compute_p_r_f_score(\n",
    "                            total_hypothesis_ngrams_count,\n",
    "                            total_reference_ngrams_count,\n",
    "                            total_ngrams_overlapping_count,\n",
    "                            self.alpha,\n",
    "                            self.weight_factor if use_w else 1.0,\n",
    "                        )\n",
    "\n",
    "                        if use_w:\n",
    "                            reference_count_for_score = reference_count ** (\n",
    "                                1.0 / self.weight_factor\n",
    "                            )\n",
    "                            overlapping_ngrams_for_score = overlapping_ngrams\n",
    "                            score_wlcs = (\n",
    "                                overlapping_ngrams_for_score / reference_count_for_score\n",
    "                            ) ** (1.0 / self.weight_factor)\n",
    "\n",
    "                            if (\n",
    "                                best_current_score_wlcs is None\n",
    "                                or score_wlcs > best_current_score_wlcs\n",
    "                            ):\n",
    "                                best_current_score = score\n",
    "                                best_current_score_wlcs = score_wlcs\n",
    "                        else:\n",
    "                            if best_current_score is None or score[\"r\"] > best_current_score[\"r\"]:\n",
    "                                best_current_score = score\n",
    "\n",
    "                    for stat in Rouge.STATS:\n",
    "                        scores[metric][stat] += best_current_score[stat]\n",
    "                # Keep all\n",
    "                else:\n",
    "                    for reference_sentences in references_sentences:\n",
    "                        (\n",
    "                            hypothesis_count,\n",
    "                            reference_count,\n",
    "                            overlapping_ngrams,\n",
    "                        ) = Rouge._compute_ngrams_lcs(\n",
    "                            hypothesis_sentences,\n",
    "                            reference_sentences,\n",
    "                            self.weight_factor if use_w else 1.0,\n",
    "                        )\n",
    "                        score = Rouge._compute_p_r_f_score(\n",
    "                            hypothesis_count,\n",
    "                            reference_count,\n",
    "                            overlapping_ngrams,\n",
    "                            self.alpha,\n",
    "                            self.weight_factor,\n",
    "                        )\n",
    "\n",
    "                        for stat in Rouge.STATS:\n",
    "                            scores[metric][sample_id][stat].append(score[stat])\n",
    "\n",
    "        # Compute final score with the average or the the max\n",
    "        if (self.apply_avg or self.apply_best) and len(all_hypothesis) > 1:\n",
    "            for stat in Rouge.STATS:\n",
    "                scores[metric][stat] /= len(all_hypothesis)\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def _preprocess_summary_as_a_whole(self, summary):\n",
    "        sentences = Rouge.split_into_sentences(summary)\n",
    "\n",
    "        # Truncate\n",
    "        if self.limit_length:\n",
    "            # By words\n",
    "            if self.length_limit_type == \"words\":\n",
    "                summary = \" \".join(sentences)\n",
    "                all_tokens = summary.split()  # Counting as in the perls script\n",
    "                summary = \" \".join(all_tokens[: self.length_limit])\n",
    "\n",
    "            # By bytes\n",
    "            elif self.length_limit_type == \"bytes\":\n",
    "                summary = \"\"\n",
    "                current_len = 0\n",
    "                for sentence in sentences:\n",
    "                    sentence = sentence.strip()\n",
    "                    sentence_len = len(sentence)\n",
    "\n",
    "                    if current_len + sentence_len < self.length_limit:\n",
    "                        if current_len != 0:\n",
    "                            summary += \" \"\n",
    "                        summary += sentence\n",
    "                        current_len += sentence_len\n",
    "                    else:\n",
    "                        if current_len > 0:\n",
    "                            summary += \" \"\n",
    "                        summary += sentence[: self.length_limit - current_len]\n",
    "                        break\n",
    "        else:\n",
    "            summary = \" \".join(sentences)\n",
    "\n",
    "        summary = Rouge.REMOVE_CHAR_PATTERN.sub(\" \", summary.lower()).strip()\n",
    "\n",
    "        tokens = self.tokenize_text(\n",
    "            Rouge.REMOVE_CHAR_PATTERN.sub(\" \", summary))\n",
    "        preprocessed_summary = [\" \".join(tokens)]\n",
    "\n",
    "        return preprocessed_summary\n",
    "\n",
    "    def _preprocess_summary_per_sentence(self, summary):\n",
    "        sentences = Rouge.split_into_sentences(summary)\n",
    "\n",
    "        # Truncate\n",
    "        if self.limit_length:\n",
    "            final_sentences = []\n",
    "            current_len = 0\n",
    "            # By words\n",
    "            if self.length_limit_type == \"words\":\n",
    "                for sentence in sentences:\n",
    "                    tokens = sentence.strip().split()\n",
    "                    tokens_len = len(tokens)\n",
    "                    if current_len + tokens_len < self.length_limit:\n",
    "                        sentence = \" \".join(tokens)\n",
    "                        final_sentences.append(sentence)\n",
    "                        current_len += tokens_len\n",
    "                    else:\n",
    "                        sentence = \" \".join(\n",
    "                            tokens[: self.length_limit - current_len])\n",
    "                        final_sentences.append(sentence)\n",
    "                        break\n",
    "            # By bytes\n",
    "            elif self.length_limit_type == \"bytes\":\n",
    "                for sentence in sentences:\n",
    "                    sentence = sentence.strip()\n",
    "                    sentence_len = len(sentence)\n",
    "                    if current_len + sentence_len < self.length_limit:\n",
    "                        final_sentences.append(sentence)\n",
    "                        current_len += sentence_len\n",
    "                    else:\n",
    "                        sentence = sentence[: self.length_limit - current_len]\n",
    "                        final_sentences.append(sentence)\n",
    "                        break\n",
    "            sentences = final_sentences\n",
    "\n",
    "        final_sentences = []\n",
    "        for sentence in sentences:\n",
    "            sentence = Rouge.REMOVE_CHAR_PATTERN.sub(\n",
    "                \" \", sentence.lower()).strip()\n",
    "\n",
    "            tokens = self.tokenize_text(\n",
    "                Rouge.REMOVE_CHAR_PATTERN.sub(\" \", sentence))\n",
    "\n",
    "            sentence = \" \".join(tokens)\n",
    "\n",
    "            final_sentences.append(sentence)\n",
    "\n",
    "        return final_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\KoBART\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'더불어민주당 이해찬 대표가 30 일 기자간담회를 열고 조국 전 법무부 장관 사태와 관련해 \"국민 여러분께 매우 송구하다\"\"는 입장을 밝혔는데 당 지도부가 겸허하게 책임지는 모습을 보이는 게 쇄신의 출발점이 돼야 한다는 지적이 나오고 있다.'\n",
      "{'rouge-2': {'f': 0.10526315789473684, 'p': 0.07017543859649122, 'r': 0.21052631578947367}, 'rouge-1': {'f': 0.282051282051282, 'p': 0.1896551724137931, 'r': 0.55}, 'rouge-l': {'f': 0.25641025641025644, 'p': 0.1724137931034483, 'r': 0.5}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers.models.bart import BartForConditionalGeneration\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained('./kobart_summary')\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')\n",
    "\n",
    "text = '''\n",
    "\"'더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부 장관 사태와 관련해 \"\"국민 여러분께 매우 송구하다\"\"고 밝혔다.'\n",
    " '더불어민주당 이해찬 대표가 30 일 기자간담회를 열고 \\'조국 사태\\'와 관련 \"\"국민 여러분께 매우 송구하다\"\"는 입장을 밝혔다.' \n",
    " '이 대표는 \"\"검찰 개혁이란 대의에 집중하다 보니 국민 특히 청년이 느꼈을 불공정에 대한 상대적 박탈감 좌절감을 깊이 있게 헤아리지 못했다\"\"며 \"\"여당 대표로서 무거운 책임감을 느낀다\"\"고 머리를 숙였다.' \n",
    " '조국 전 법무부 장관이 14 일 사퇴한 이후 이 대표가 당 안팎의 쇄신 요구에 대해 입장을 표명한 것은 이번이 처음이다.' \"\"청와대와 여당은 '조국 정국'을 거치며 분출된 '공정'과 '정의'의 민심을 받들어 검찰 개혁에 매진하겠다면서도 두 달간 극심한 분열과 갈등을 초래한데 대해선 진지하게 성찰하는 모습을 보이지 않았다.\"\" '그나마 초선인 이철희 의원이 \"\"당이 대통령 뒤에 비겁하게 숨어 있었다\"\"고 비판했고 표창원 의원은 \"\"책임을 느끼는 분들이 각자 형태로 그 책임감을 행동으로 옮겨야 할 때\"\"라고 지적했다.' '뒤늦게나마 이 대표가 자성의 목소리를 내긴 했으나 당 안팎의 쇄신 요구에 어떻게 응할지 구체적 플랜을 제시하지 못해 여전히 안이하다는 지적도 나온다.' '이 대표는 28 일 윤호중 사무총장을 단장으로 하는 총선기획단을 발족했고 조만간 인재영입위원회도 출범시킬 계획이라고 밝혔다.' '이 대표는 \"\"민주당의 가치를 공유하는 참신한 인물을 영입해 준비된 정책과 인물로 승부하겠다\"\"고 다짐했다.' '하지만 당 일각에선 \"\"총선기획단장을 비롯한 당직 인선부터 쇄신 의지를 보여야 한다\"\"는 비판의 목소리가 나온다.' '무조건 물러나는 게 능사는 아니지만 국정 혼선을 초래한 데 대해 당 지도부가 겸허하게 책임지는 모습을 보이는 게 쇄신의 출발점이 돼야 한다는 지적도 있다.' '선거는 대중의 이해와 요구를 잘 대표하는 정치인을 뽑는 행위다.' '민생을 외면하며 낡은 이념과 진영 싸움에 매몰된 구시대 인물들을 과감히 물갈이하라는 게 국민의 요구다.' '대신 4 차 산업혁명의 거센 파고를 헤쳐나갈 전문성을 갖춘 젊고 유능한 인재들을 널리 구해야 하다.' '이해찬 대표의 이날 유감 표명이 여권 전반의 대대적인 인적 쇄신으로 이어지길 기대한다.'\"\n",
    "'''\n",
    "\n",
    "\n",
    "text = text.replace('\\n', ' ')\n",
    "\n",
    "raw_input_ids = tokenizer.encode(text)\n",
    "input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
    "output = tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(output)\n",
    "\n",
    "correct_answer = \"이해찬 대표가 조국 사태와 관련 송구한 입장 표명이 과감한 인적 쇄신으로 이어져야 한다.\"\n",
    "\n",
    "rouge = Rouge(metrics=['rouge-l', 'rouge-n'])\n",
    "\n",
    "rouge_n = [0,0,0]   #각각 f,p,r\n",
    "rouge_l = [0,0,0]   #각각 f,p,r\n",
    "\n",
    "result = rouge.get_scores(output, correct_answer)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make index list\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "json_data=[]\n",
    "psg_tsv = [] # 원본\n",
    "psg_tsv_str=[]\n",
    "smy_tsv = [] # 요약\n",
    "smy_tsv_str=[]\n",
    "\n",
    "def listToString(str_list):\n",
    "    result = \"\"\n",
    "    for s in str_list:\n",
    "        result += s + \" \"\n",
    "    return result.strip()\n",
    "\n",
    "with open('./dacondata/test.json') as f:\n",
    "    for line in f:\n",
    "        # line은 String 값 \n",
    "        json_data.append(json.loads(line)) # 전체데이터 딕셔너리 형태로 넣기 \n",
    "\n",
    "    num = 0\n",
    "    for json_num_list in json_data:\n",
    "        psg_tsv.append(json_data[num]['article_original']) # 데이터 원문입니다.\n",
    "        psg_tsv_str.append(listToString(psg_tsv[num]))\n",
    "       \n",
    "\n",
    "        smy_tsv.append(json_data[num]['abstractive'])\n",
    "     \n",
    "    \n",
    "        num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부...</td>\n",
       "      <td>이해찬 대표가 조국 사태와 관련 송구한 입장 표명이 과감한 인적 쇄신으로 이어져야 한다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>탈원전 정책에서 비롯된 한국전력의 경영 부담이 결국 전기료 인상을 초래하게 됐다. ...</td>\n",
       "      <td>탈원전 정책에서 비롯된 한국전력의 경영 악화가 결국 전기료 인상이라는 결과를 낳아 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>북한이 그제 금강산국제관광국 명의로 통일부와 현대아산에 통지문을 보내 금강산관광 시...</td>\n",
       "      <td>북한이 통일부와 현대아산에 금강산 관광 시설 철거와 관련하여 문서 교환 방식의 협의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지난달 한국의 소비자물가상승률이 경제협력개발기구(OECD) 회원국 중 가장 낮았다....</td>\n",
       "      <td>OECD가 집계한 소비자물가 통게에서 9월 한국 상승률은 전년 동월 대비 -0.4%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김종갑 한국전력 사장이 1 조1 천억원이 넘는 각종 전기료 특례 할인을 모두 폐지하...</td>\n",
       "      <td>김종갑 한국전력 사장이 1조 1천억원 규모의 전기료 특례 할인 폐지 및 전기요금 원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>최근 만덕2터널에서 발생한 4중 추돌사고 아찔한 순간이 공개됐다. 쏘렌토 차주 A ...</td>\n",
       "      <td>부산 만덕 2터널에서 4중 추돌사고를 당한 쏘렌토 차주 A씨가 공개한 사고 순간 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>지난해 국내 손해보험사들의 대리점 수수료가 고공행진한 것으로 나타났다. 17일 손해...</td>\n",
       "      <td>17일 손해보험협회에 의하면 독립법인대리점을 통한 보험 판매가 늘면서 지난해 10개...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>LG전자가 와인 113병을 보관할 수 있는 24인치 컬럼형 '와인셀러'를 출시했다고...</td>\n",
       "      <td>LG전자는 와인을 최적으로 보관가능한 동굴 기술을 적용한 컬럼형 와인셀러 초프리미엄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...</td>\n",
       "      <td>주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>경북지역은 경쟁력 있는 과일브랜드를 육성하기 위해 2016년부터 '데일리(daily...</td>\n",
       "      <td>최근 수입 농산물 증가와 지역 지역별 군소 브랜드의 난립이 국산 농산물의 경쟁력을 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                passage  \\\n",
       "0     더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부...   \n",
       "1     탈원전 정책에서 비롯된 한국전력의 경영 부담이 결국 전기료 인상을 초래하게 됐다. ...   \n",
       "2     북한이 그제 금강산국제관광국 명의로 통일부와 현대아산에 통지문을 보내 금강산관광 시...   \n",
       "3     지난달 한국의 소비자물가상승률이 경제협력개발기구(OECD) 회원국 중 가장 낮았다....   \n",
       "4     김종갑 한국전력 사장이 1 조1 천억원이 넘는 각종 전기료 특례 할인을 모두 폐지하...   \n",
       "...                                                 ...   \n",
       "1995  최근 만덕2터널에서 발생한 4중 추돌사고 아찔한 순간이 공개됐다. 쏘렌토 차주 A ...   \n",
       "1996  지난해 국내 손해보험사들의 대리점 수수료가 고공행진한 것으로 나타났다. 17일 손해...   \n",
       "1997  LG전자가 와인 113병을 보관할 수 있는 24인치 컬럼형 '와인셀러'를 출시했다고...   \n",
       "1998  주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...   \n",
       "1999  경북지역은 경쟁력 있는 과일브랜드를 육성하기 위해 2016년부터 '데일리(daily...   \n",
       "\n",
       "                                                summary  \n",
       "0     이해찬 대표가 조국 사태와 관련 송구한 입장 표명이 과감한 인적 쇄신으로 이어져야 한다.  \n",
       "1     탈원전 정책에서 비롯된 한국전력의 경영 악화가 결국 전기료 인상이라는 결과를 낳아 ...  \n",
       "2     북한이 통일부와 현대아산에 금강산 관광 시설 철거와 관련하여 문서 교환 방식의 협의...  \n",
       "3     OECD가 집계한 소비자물가 통게에서 9월 한국 상승률은 전년 동월 대비 -0.4%...  \n",
       "4     김종갑 한국전력 사장이 1조 1천억원 규모의 전기료 특례 할인 폐지 및 전기요금 원...  \n",
       "...                                                 ...  \n",
       "1995  부산 만덕 2터널에서 4중 추돌사고를 당한 쏘렌토 차주 A씨가 공개한 사고 순간 영...  \n",
       "1996  17일 손해보험협회에 의하면 독립법인대리점을 통한 보험 판매가 늘면서 지난해 10개...  \n",
       "1997  LG전자는 와인을 최적으로 보관가능한 동굴 기술을 적용한 컬럼형 와인셀러 초프리미엄...  \n",
       "1998  주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...  \n",
       "1999  최근 수입 농산물 증가와 지역 지역별 군소 브랜드의 난립이 국산 농산물의 경쟁력을 ...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labeling = pd.concat([pd.DataFrame(psg_tsv_str),pd.DataFrame(smy_tsv)], axis = 1)\n",
    "test_labeling.columns = ['passage' ,'summary'] # 뉴스 학습데이터 양식 맞추기 (원문  요약문 => 탭 구분)\n",
    "test_labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부...</td>\n",
       "      <td>이해찬 대표가 조국 사태와 관련 송구한 입장 표명이 과감한 인적 쇄신으로 이어져야 한다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>탈원전 정책에서 비롯된 한국전력의 경영 부담이 결국 전기료 인상을 초래하게 됐다. ...</td>\n",
       "      <td>탈원전 정책에서 비롯된 한국전력의 경영 악화가 결국 전기료 인상이라는 결과를 낳아 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>북한이 그제 금강산국제관광국 명의로 통일부와 현대아산에 통지문을 보내 금강산관광 시...</td>\n",
       "      <td>북한이 통일부와 현대아산에 금강산 관광 시설 철거와 관련하여 문서 교환 방식의 협의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지난달 한국의 소비자물가상승률이 경제협력개발기구(OECD) 회원국 중 가장 낮았다....</td>\n",
       "      <td>OECD가 집계한 소비자물가 통게에서 9월 한국 상승률은 전년 동월 대비 -0.4%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김종갑 한국전력 사장이 1 조1 천억원이 넘는 각종 전기료 특례 할인을 모두 폐지하...</td>\n",
       "      <td>김종갑 한국전력 사장이 1조 1천억원 규모의 전기료 특례 할인 폐지 및 전기요금 원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>최근 만덕2터널에서 발생한 4중 추돌사고 아찔한 순간이 공개됐다. 쏘렌토 차주 A ...</td>\n",
       "      <td>부산 만덕 2터널에서 4중 추돌사고를 당한 쏘렌토 차주 A씨가 공개한 사고 순간 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>지난해 국내 손해보험사들의 대리점 수수료가 고공행진한 것으로 나타났다. 17일 손해...</td>\n",
       "      <td>17일 손해보험협회에 의하면 독립법인대리점을 통한 보험 판매가 늘면서 지난해 10개...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>LG전자가 와인 113병을 보관할 수 있는 24인치 컬럼형 '와인셀러'를 출시했다고...</td>\n",
       "      <td>LG전자는 와인을 최적으로 보관가능한 동굴 기술을 적용한 컬럼형 와인셀러 초프리미엄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...</td>\n",
       "      <td>주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>경북지역은 경쟁력 있는 과일브랜드를 육성하기 위해 2016년부터 '데일리(daily...</td>\n",
       "      <td>최근 수입 농산물 증가와 지역 지역별 군소 브랜드의 난립이 국산 농산물의 경쟁력을 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                passage  \\\n",
       "0     더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부...   \n",
       "1     탈원전 정책에서 비롯된 한국전력의 경영 부담이 결국 전기료 인상을 초래하게 됐다. ...   \n",
       "2     북한이 그제 금강산국제관광국 명의로 통일부와 현대아산에 통지문을 보내 금강산관광 시...   \n",
       "3     지난달 한국의 소비자물가상승률이 경제협력개발기구(OECD) 회원국 중 가장 낮았다....   \n",
       "4     김종갑 한국전력 사장이 1 조1 천억원이 넘는 각종 전기료 특례 할인을 모두 폐지하...   \n",
       "...                                                 ...   \n",
       "1995  최근 만덕2터널에서 발생한 4중 추돌사고 아찔한 순간이 공개됐다. 쏘렌토 차주 A ...   \n",
       "1996  지난해 국내 손해보험사들의 대리점 수수료가 고공행진한 것으로 나타났다. 17일 손해...   \n",
       "1997  LG전자가 와인 113병을 보관할 수 있는 24인치 컬럼형 '와인셀러'를 출시했다고...   \n",
       "1998  주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...   \n",
       "1999  경북지역은 경쟁력 있는 과일브랜드를 육성하기 위해 2016년부터 '데일리(daily...   \n",
       "\n",
       "                                                summary  \n",
       "0     이해찬 대표가 조국 사태와 관련 송구한 입장 표명이 과감한 인적 쇄신으로 이어져야 한다.  \n",
       "1     탈원전 정책에서 비롯된 한국전력의 경영 악화가 결국 전기료 인상이라는 결과를 낳아 ...  \n",
       "2     북한이 통일부와 현대아산에 금강산 관광 시설 철거와 관련하여 문서 교환 방식의 협의...  \n",
       "3     OECD가 집계한 소비자물가 통게에서 9월 한국 상승률은 전년 동월 대비 -0.4%...  \n",
       "4     김종갑 한국전력 사장이 1조 1천억원 규모의 전기료 특례 할인 폐지 및 전기요금 원...  \n",
       "...                                                 ...  \n",
       "1995  부산 만덕 2터널에서 4중 추돌사고를 당한 쏘렌토 차주 A씨가 공개한 사고 순간 영...  \n",
       "1996  17일 손해보험협회에 의하면 독립법인대리점을 통한 보험 판매가 늘면서 지난해 10개...  \n",
       "1997  LG전자는 와인을 최적으로 보관가능한 동굴 기술을 적용한 컬럼형 와인셀러 초프리미엄...  \n",
       "1998  주방가전 전문업체 ㈜리빙코리아가 최근 선보인 '2019년형 리빙웰 에어프라이어'가 ...  \n",
       "1999  최근 수입 농산물 증가와 지역 지역별 군소 브랜드의 난립이 국산 농산물의 경쟁력을 ...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test_labeling\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "df['passage'] \n",
    "print(len(df['passage']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부 장관 사태와 관련해 \"국민 여러분께 매우 송구하다\"고 밝혔다. 더불어민주당 이해찬 대표가 30 일 기자간담회를 열고 \\'조국 사태\\'와 관련, \"국민 여러분께 매우 송구하다\"는 입장을 밝혔다. 이 대표는 \"검찰 개혁이란 대의에 집중하다 보니, 국민 특히 청년이 느꼈을 불공정에 대한 상대적 박탈감, 좌절감을 깊이 있게 헤아리지 못했다\"며 \"여당 대표로서 무거운 책임감을 느낀다\"고 머리를 숙였다. 조국 전 법무부 장관이 14 일 사퇴한 이후 이 대표가 당 안팎의 쇄신 요구에 대해 입장을 표명한 것은 이번이 처음이다. 청와대와 여당은 \\'조국 정국\\'을 거치며 분출된 \\'공정\\'과 \\'정의\\'의 민심을 받들어 검찰 개혁에 매진하겠다면서도 두 달간 극심한 분열과 갈등을 초래한데 대해선 진지하게 성찰하는 모습을 보이지 않았다. 그나마 초선인 이철희 의원이 \"당이 대통령 뒤에 비겁하게 숨어 있었다\"고 비판했고, 표창원 의원은 \"책임을 느끼는 분들이 각자 형태로 그 책임감을 행동으로 옮겨야 할 때\"라고 지적했다. 뒤늦게나마 이 대표가 자성의 목소리를 내긴 했으나 당 안팎의 쇄신 요구에 어떻게 응할지 구체적 플랜을 제시하지 못해 여전히 안이하다는 지적도 나온다. 이 대표는 28 일 윤호중 사무총장을 단장으로 하는 총선기획단을 발족했고 조만간 인재영입위원회도 출범시킬 계획이라고 밝혔다. 이 대표는 \"민주당의 가치를 공유하는 참신한 인물을 영입해 준비된 정책과 인물로 승부하겠다\"고 다짐했다. 하지만 당 일각에선 \"총선기획단장을 비롯한 당직 인선부터 쇄신 의지를 보여야 한다\"는 비판의 목소리가 나온다. 무조건 물러나는 게 능사는 아니지만 국정 혼선을 초래한 데 대해 당 지도부가 겸허하게 책임지는 모습을 보이는 게 쇄신의 출발점이 돼야 한다는 지적도 있다. 선거는 대중의 이해와 요구를 잘 대표하는 정치인을 뽑는 행위다. 민생을 외면하며 낡은 이념과 진영 싸움에 매몰된 구시대 인물들을 과감히 물갈이하라는 게 국민의 요구다. 대신 4 차 산업혁명의 거센 파고를 헤쳐나갈 전문성을 갖춘 젊고 유능한 인재들을 널리 구해야 하다. 이해찬 대표의 이날 유감 표명이 여권 전반의 대대적인 인적 쇄신으로 이어지길 기대한다.', '탈원전 정책에서 비롯된 한국전력의 경영 부담이 결국 전기료 인상을 초래하게 됐다. 김종갑 한전 사장은 언론 인터뷰에서 \"정부 정책에 따라 도입된 각종 전기료 특례할인을 모두 폐지하고 전기요금 원가공개 방안을 정부와 협의하겠다\"고 밝혔다. 특례할인은 여름철 누진제, 주택용 절전 및 전기차 충전 등의 명목으로 전기료를 깎아주는 제도로서, 작년 1 조 1434 억원에 달했다. 이 제도가 없어지면 부담은 고스란히 국민에게 돌아가게 된다. 전기료 인상은 예견됐던 것이나 마찬가지다. 문재인 정부 출범 이후 탈원전 정책이 가속화되면서 한전 경영이 악화일로를 달려왔기 때문이다. 원전 가동을 줄이고 발전 단가가 높은 민간 발전사의 전기 구매를 늘린 탓에 한전의 발전 원가는 2016 년 25 조원 수준에서 2018 년 38 조원 수준으로 급등했다. 영업이익이 같은 기간 12 조 16 억원 흑자에서 2080 억원 적자로 급반전한 것은 필연적인 결과다. 적자는 올해 상반기 9285 억원으로 더 불어났다. 우량회사가 2 년여 만에 적자의 수렁에 처박힌 꼴이다. 한전의 추락은 국제신용평가사들의 평가에도 그대로 적용된다. S&P는 그제 한전의 신용등급을 기존 BBB에서 BBB-로 내렸다. 탈원전 정책의 충격이 커지면서 재무 부담이 가중되고 있다는 게 하향 조정 이유다. 표면적으로는 \\'재무 부담\\'이란 용어를 사용했지만 한전의 기초체력이 급속히 악화되고 있다는 경고와 다를 바 없다. S&P가 한전의 주요 재무지표에 대해 앞으로 1~2 년간 개선되기 어렵다고 밝힌 점으로 미뤄 신용등급의 추가 하향 조정 가능성도 배제하기 어렵다. 이런 상황에서도 정부는 다음달부터 연말까지 전력효율이 높은 가전제품을 사면 구입가의 10%를 환급해 준다며 한전 출연금을 재원의 일부로 사용하기로 했다. \"탈원전으로 전기료 인상은 없다\"고 공언하며 한전을 망가뜨린 것도 모자라 한전 돈으로 생색내기에 나선 모양새다. 한전의 앞날과 더 늘어날 국민 부담을 고민한다면 정부는 이제라도 탈원전 속도를 조절하면서 무엇이 옳은지 냉정히 따져야 한다. 한전을 빈껍데기로 만들고 전기료 인상을 잠시 미룬다 해도 그 부담은 결국 국민 몫으로 한꺼번에 돌아올 뿐이다.']\n",
      "['이해찬 대표가 조국 사태와 관련 송구한 입장 표명이 과감한 인적 쇄신으로 이어져야 한다.', '탈원전 정책에서 비롯된 한국전력의 경영 악화가 결국 전기료 인상이라는 결과를 낳아 \"탈원전으로 전기료 인상은 없다\"고 공언한 정부는 한전의 앞날과 더 늘어날 국민 부담을 고민하고 이제라도 탈원전 속도를 조절하면서 무엇이 옳은지 냉정히 따져야 한다.']\n"
     ]
    }
   ],
   "source": [
    "#데이터프레임을 리스트로 변환 \n",
    "passage_df = df['passage'].values.tolist()\n",
    "summary_df = df['summary'].values.tolist()\n",
    "print(passage_df[0:2])\n",
    "print(summary_df[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-2': {'f': 0.10666666666666667, 'p': 0.07142857142857142, 'r': 0.21052631578947367}, 'rouge-1': {'f': 0.3116883116883116, 'p': 0.21052631578947367, 'r': 0.6}, 'rouge-l': {'f': 0.2597402597402597, 'p': 0.17543859649122806, 'r': 0.5}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20132\\3202249826.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbos_token_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mraw_input_ids\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0msummary_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mnum_beams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0meos_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\KoBART\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\KoBART\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   1061\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m             )\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\KoBART\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   1792\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1794\u001b[1;33m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1795\u001b[0m             )\n\u001b[0;32m   1796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\KoBART\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\KoBART\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1308\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m         )\n\u001b[1;32m-> 1310\u001b[1;33m         \u001b[0mlm_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m         \u001b[0mmasked_lm_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\KoBART\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\KoBART\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers.models.bart import BartForConditionalGeneration\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = []\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained('./kobart_summary')\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')\n",
    "\n",
    "for i in range(2000):\n",
    "    text = passage_df[i]\n",
    "    text = text.replace('\\n', ' ')\n",
    "\n",
    "\n",
    "    raw_input_ids = tokenizer.encode(text)\n",
    "    input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "    summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
    "    output = tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n",
    "\n",
    "    correct_answer = summary_df[i]\n",
    "\n",
    "    rouge = Rouge(metrics=['rouge-l', 'rouge-n'])\n",
    "\n",
    "    rouge_n = [0,0,0]   #각각 f,p,r\n",
    "    rouge_l = [0,0,0]   #각각 f,p,r\n",
    "\n",
    "    result = rouge.get_scores(output, correct_answer)\n",
    "    # print(result) \n",
    "    # {'rouge-2': {'f': 0.10666666666666667, 'p': 0.07142857142857142, 'r': 0.21052631578947367},\n",
    "    #  'rouge-1': {'f': 0.3116883116883116,  'p': 0.21052631578947367, 'r': 0.6},\n",
    "    #  'rouge-l': {'f': 0.2597402597402597,  'p': 0.17543859649122806, 'r': 0.5}}\n",
    "\n",
    "\n",
    "    #print(type(result))\n",
    "    #print(result)\n",
    "    #print(result.keys())\n",
    "    #print(result.values())\n",
    "    #print(result['rouge-2']['f'])\n",
    "\n",
    "    data.append({\n",
    "            'Input Text': text,\n",
    "            'Correct Answer': correct_answer,\n",
    "            'Generated Summary': output,\n",
    "            'Rouge Scores': result\n",
    "        })\n",
    "    \n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv = r'D:\\t3q\\KoBART\\KoBART-summarization\\output\\output.csv'\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"Summary and Rouge scores saved to\", output_csv)\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "# Calculate Rouge statistics\n",
    "rouge_l_f_scores = [score['rouge-l']['f'] for score in df['Rouge Scores']]\n",
    "rouge_1_f_scores = [score['rouge-1']['f'] for score in df['Rouge Scores']]\n",
    "rouge_2_f_scores = [score['rouge-2']['f'] for score in df['Rouge Scores']]\n",
    "\n",
    "\n",
    "# Calculate Rouge metrics\n",
    "rouge_avg_l = sum(rouge_l_f_scores) / len(rouge_l_f_scores)\n",
    "rouge_max_l = max(rouge_l_f_scores)\n",
    "rouge_min_l = min(rouge_l_f_scores)\n",
    "\n",
    "rouge_avg_1 = sum(rouge_1_f_scores) / len(rouge_1_f_scores)\n",
    "rouge_max_1 = max(rouge_1_f_scores)\n",
    "rouge_min_1 = min(rouge_1_f_scores)\n",
    "\n",
    "rouge_avg_2 = sum(rouge_2_f_scores) / len(rouge_2_f_scores)\n",
    "rouge_max_2 = max(rouge_2_f_scores)\n",
    "rouge_min_2 = min(rouge_2_f_scores)\n",
    "\n",
    "print(\"Average Rouge-l F-score:\", rouge_avg_l)\n",
    "print(\"Maximum Rouge-l F-score:\", rouge_max_l)\n",
    "print(\"Minimum Rouge-l F-score:\", rouge_min_l)\n",
    "\n",
    "print(\"Average Rouge-1 F-score:\", rouge_avg_1)\n",
    "print(\"Maximum Rouge-1 F-score:\", rouge_max_1)\n",
    "print(\"Minimum Rouge-1 F-score:\", rouge_min_1)\n",
    "\n",
    "print(\"Average Rouge-2 F-score:\", rouge_avg_2)\n",
    "print(\"Maximum Rouge-2 F-score:\", rouge_max_2)\n",
    "print(\"Minimum Rouge-2 F-score:\", rouge_min_2)\n",
    "\n",
    "   \n",
    "\n",
    "#result.to_csv('./data/dacondata.tsv', index=False, sep=\"\\t\") # sep활용하여 tab 구분 정의\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T3Q",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
